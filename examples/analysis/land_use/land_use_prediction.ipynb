{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca319ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from blocksnet.analysis.land_use.prediction import SpatialClassifier\n",
    "from blocksnet.machine_learning.strategy.sklearn.ensemble.voting.classification_strategy import SKLearnVotingClassificationStrategy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e73f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_gdfs(root: str | Path, pattern: str = \"*.pkl\", target_crs: str | None = None) -> list[gpd.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    –ó–∞–≥—Ä—É–∂–∞–µ—Ç GeoDataFrame'—ã –∏–∑ .pkl —Ñ–∞–π–ª–æ–≤:\n",
    "      - –µ—Å–ª–∏ root —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –æ–¥–∏–Ω .pkl —Ñ–∞–π–ª ‚Äî —á–∏—Ç–∞–µ–º –µ–≥–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ [GDF]\n",
    "      - –µ—Å–ª–∏ root ‚Äî –ø–∞–ø–∫–∞ ‚Äî —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ–º –ø–æ –º–∞—Å–∫–µ pattern –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ GDF\n",
    "\n",
    "    –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Å—Ç–æ–ª–±—Ü—ã 'city' –∏ 'country' –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—É—Ç–µ–π:\n",
    "    .../<country>/<city>/<file>.pkl\n",
    "\n",
    "    Args:\n",
    "        root: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É .pkl –∏–ª–∏ –ø–∞–ø–∫–µ\n",
    "        pattern: –º–∞—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é \"*.pkl\") ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ root –ø–∞–ø–∫–∞\n",
    "        target_crs: –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –ø—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ –≥–µ–æ–¥–∞–Ω–Ω—ã–µ –∫ —ç—Ç–æ–º—É CRS\n",
    "\n",
    "    Returns:\n",
    "        list[GeoDataFrame]\n",
    "    \"\"\"\n",
    "    p = Path(root)\n",
    "\n",
    "    def _ensure_gdf(obj):\n",
    "        \"\"\"–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–±—ä–µ–∫—Ç –≤ GeoDataFrame, –µ—Å–ª–∏ —ç—Ç–æ DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π 'geometry'.\"\"\"\n",
    "        if isinstance(obj, gpd.GeoDataFrame):\n",
    "            return obj\n",
    "        if isinstance(obj, pd.DataFrame) and \"geometry\" in obj.columns:\n",
    "            return gpd.GeoDataFrame(obj, geometry=\"geometry\", crs=getattr(obj, \"crs\", None))\n",
    "        return None\n",
    "\n",
    "    def _infer_city_country(fp: Path):\n",
    "        # –æ–∂–∏–¥–∞–µ–º .../<country>/<city>/<file>.pkl\n",
    "        city = fp.name[:-4] if fp else None\n",
    "        country = fp.parent.name if len(fp.parents) >= 2 else None\n",
    "        return city, country\n",
    "\n",
    "    # –°–æ–±–µ—Ä—ë–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤\n",
    "    if p.is_file() and p.suffix.lower() == \".pkl\":\n",
    "        files = [p]\n",
    "    elif p.is_dir():\n",
    "        files = sorted(p.rglob(pattern))\n",
    "        files = [f for f in files if f.suffix.lower() == \".pkl\"]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    gdfs: list[gpd.GeoDataFrame] = []\n",
    "\n",
    "    for fp in files:\n",
    "        try:\n",
    "            with open(fp, \"rb\") as f:\n",
    "                obj = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"–ü—Ä–æ–ø—É—Å–∫–∞—é {fp}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # –ï—Å–ª–∏ GeoDataFrame\n",
    "        gdf = _ensure_gdf(obj)\n",
    "\n",
    "        # –ï—Å–ª–∏ dict —Å GeoDataFrame\n",
    "        if gdf is None and isinstance(obj, dict):\n",
    "            for k, v in obj.items():\n",
    "                gi = _ensure_gdf(v)\n",
    "                if gi is None:\n",
    "                    continue\n",
    "                gi = gi.copy()\n",
    "                if \"city\" not in gi.columns or gi[\"city\"].isna().all():\n",
    "                    gi[\"city\"] = str(k)\n",
    "                _, country = _infer_city_country(fp)\n",
    "                if (\"country\" not in gi.columns) and country:\n",
    "                    gi[\"country\"] = country\n",
    "                if target_crs:\n",
    "                    gi = gi.to_crs(target_crs) if gi.crs else gi.set_crs(target_crs)\n",
    "                gdfs.append(gi)\n",
    "            continue\n",
    "\n",
    "        if gdf is None:\n",
    "            print(f\"–ü—Ä–æ–ø—É—Å–∫–∞—é {fp}: –æ–±—ä–µ–∫—Ç –Ω–µ GeoDataFrame –∏ –Ω–µ dict —Å GeoDataFrame.\")\n",
    "            continue\n",
    "\n",
    "        gdf = gdf.copy()\n",
    "        city, country = _infer_city_country(fp)\n",
    "        if \"city\" not in gdf.columns:\n",
    "            gdf[\"city\"] = city or fp.stem\n",
    "        if (\"country\" not in gdf.columns) and country:\n",
    "            gdf[\"country\"] = country\n",
    "\n",
    "        if target_crs:\n",
    "            gdf = gdf.to_crs(target_crs) if gdf.crs else gdf.set_crs(target_crs)\n",
    "\n",
    "        gdfs.append(gdf)\n",
    "\n",
    "    return gdfs\n",
    "\n",
    "MERGE_DICT = {\n",
    "    'LandUse.RECREATION': 'non_urban',\n",
    "    'LandUse.SPECIAL': 'non_urban',\n",
    "    'LandUse.AGRICULTURE': 'non_urban',\n",
    "    'LandUse.BUSINESS': 'urban',\n",
    "    'LandUse.RESIDENTIAL': 'urban',\n",
    "    'LandUse.INDUSTRIAL': 'industrial',\n",
    "    'LandUse.TRANSPORT': None,    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "russia = load_gdfs('data/blocks/Russia/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07fc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ\n",
    "BASE_PARAMS = {\"random_state\": 42, \"n_jobs\": -1}\n",
    "CPU = max(1, min(8, os.cpu_count() or 1))\n",
    "MODEL_PARAMS = {\n",
    "    \"rf\": {\n",
    "        \"n_estimators\": 120,          # –±—ã–ª–æ 200\n",
    "        \"max_depth\": 7,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"max_samples\": 0.25,          # üî¥ –±—ç–≥–≥–∏–Ω–≥ –Ω–∞ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ\n",
    "        \"min_samples_leaf\": 10,       # —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –∏ –º–µ–Ω—å—à–µ —É–∑–ª–æ–≤\n",
    "        **BASE_PARAMS\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"n_estimators\": 150,          # –º–µ–Ω—å—à–µ\n",
    "        \"max_depth\": 7,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"subsample\": 0.8,             # —Å—Ç–∞—Ö–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"tree_method\": \"hist\",        # –ø–∞–º—è—Ç—å/—Å–∫–æ—Ä–æ—Å—Ç—å\n",
    "        \"n_jobs\": CPU                 # XGB –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç BASE_PARAMS –µ—Å–ª–∏ –µ–≥–æ —Å—Ç–µ—Ä–ª–∏\n",
    "    },\n",
    "    \"lgb\": {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 7,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"num_threads\": CPU            # —É LGB –ø–∞—Ä–∞–º–µ—Ç—Ä –¥—Ä—É–≥–æ–µ –∏–º—è\n",
    "    },\n",
    "    \"hgb\": {\n",
    "        \"max_iter\": 200,\n",
    "        \"max_depth\": 7,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "}\n",
    "estimators = [\n",
    "    (\"rf\",  RandomForestClassifier(**MODEL_PARAMS[\"rf\"])),\n",
    "    (\"xgb\", XGBClassifier(**MODEL_PARAMS[\"xgb\"])),\n",
    "    (\"lgb\", LGBMClassifier(**MODEL_PARAMS[\"lgb\"])),\n",
    "    (\"hgb\", HistGradientBoostingClassifier(**MODEL_PARAMS[\"hgb\"])),\n",
    "]\n",
    "\n",
    "strategy = SKLearnVotingClassificationStrategy(estimators, {\"voting\": \"soft\", \"n_jobs\": -1})\n",
    "classifier = SpatialClassifier(strategy, 1000, 5)\n",
    "score = classifier.train(russia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SpatialClassifier.default()\n",
    "result = classifier.run(russia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
